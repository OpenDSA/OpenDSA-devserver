# Python
import datetime

# Django
from django.db import models
from django.core.urlresolvers import reverse
from django.db.models import Q
from django.db import transaction
from django.core.validators import RegexValidator
from django.utils.translation import ugettext_lazy as _
from django.contrib.contenttypes import generic
from django.contrib.auth.models import User


import consts
from decorators import clamp 

# Create your models here.




class Exercise(models.Model):

    name = models.CharField(max_length=50)
    short_display_name = models.CharField(default="",max_length=50)
    prerequisites = models.TextField()
    covers = models.TextField()
    v_position = models.IntegerField() # actually horizontal position on knowledge map
    h_position = models.IntegerField() # actually vertical position on knowledge map
    seconds_per_fast_problem = models.FloatField(default = consts.MIN_SECONDS_PER_FAST_PROBLEM) # Seconds expected to finish a problem 'quickly' for badge calculation

    # True if this exercise is live and visible to all users.
    # Non-live exercises are only visible to admins.
    live = models.BooleanField(default=False)

    # True if this exercise is a quasi-exercise generated by
    # combining the content of other exercises
    summative = models.BooleanField(default=False)

    # Teachers contribute raw html with embedded CSS and JS
    # and we sanitize it with Caja before displaying it to
    # students.
    author = models.CharField(max_length=50)
    raw_html = models.TextField()
    last_modified = models.DateTimeField(default="2012-01-01 00:00:00")
    creation_date = models.DateTimeField(default="2012-01-01 00:00:00")
    description = models.TextField()
    tags = models.TextField()
    _serialize_blacklist = [
            "author", "raw_html", "last_modified",
            "coverers", "prerequisites_ex", "assigned",
            ]

    @staticmethod
    def get_relative_url(exercise_name):
        return "/exercise/%s" % exercise_name

    @property
    def relative_url(self):
        return Exercise.get_relative_url(self.name)

    @property
    def ka_url(self):
        return util.absolute_url(self.relative_url)

    @staticmethod
    def get_by_name(name, version=None):
        dict_exercises = Exercise._get_dict_use_cache_unsafe()
        if dict_exercises.has_key(name):
            if dict_exercises[name].is_visible_to_current_user():
                exercise = dict_exercises[name]
                # if there is a version check to see if there are any updates to the video
                if version:
                    change = VersionContentChange.get_change_for_content(exercise, version)
                    if change:
                        exercise = change.updated_content(exercise)
                return exercise
        return None

    @staticmethod
    def to_display_name(name):
        if name:
            return name.replace('_', ' ').capitalize()
        return ""

    @property
    def display_name(self):
        return Exercise.to_display_name(self.name)

    # The number of "sub-bars" in a summative (equivalently, # of save points + 1)
    @property
    def num_milestones(self):
        return len(self.prerequisites) if self.summative else 1

    @staticmethod
    def to_short_name(name):
        exercise = Exercise.get_by_name(name)
        return exercise.short_name() if exercise else ""

    def short_name(self):
        return (self.short_display_name or self.display_name)[:11]

    def is_visible_to_current_user(self):
        return self.live or user_util.is_current_user_developer()

    def summative_children(self):
        if not self.summative:
            return []
        query = models.Query(Exercise)
        query.filter("name IN ", self.prerequisites)
        return query

    def non_summative_exercise(self, problem_number):
        if not self.summative:
            return self

        if len(self.prerequisites) <= 0:
            raise Exception("Summative exercise '%s' does not include any other exercises" % self.name)

        # For now we just cycle through all of the included exercises in a summative exercise
        index = int(problem_number) % len(self.prerequisites)
        exid = self.prerequisites[index]

        query = Exercise.all()
        query.filter('name =', exid)
        exercise = query.get()

        if not exercise:
            raise Exception("Unable to find included exercise")

        if exercise.summative:
            return exercise.non_summative_exercise(problem_number)
        else:
            return exercise

    def related_videos_query(self):
        query = ExerciseVideo.all()
        query.filter('exercise =', self.key()).order('exercise_order')
        return query


    # followup_exercises reverse walks the prerequisites to give you
    # the exercises that list the current exercise as its prerequisite.
    # i.e. follow this exercise up with these other exercises
    def followup_exercises(self):
        return [exercise for exercise in Exercise.get_all_use_cache() if self.name in exercise.prerequisites]

    @classmethod
    def all(cls, live_only = False, **kwargs):
        query = super(Exercise, cls).all(**kwargs)
        if live_only or not user_util.is_current_user_developer():
            query.filter("live =", True)
        return query
    @classmethod
    def all_unsafe(cls):
        return super(Exercise, cls).all()

    @staticmethod
    def get_all_use_cache():
        if user_util.is_current_user_developer():
            return Exercise._get_all_use_cache_unsafe()
        else:
            return Exercise._get_all_use_cache_safe()


    @staticmethod
    def _get_all_use_cache_safe():
        return filter(lambda exercise: exercise.live, Exercise._get_all_use_cache_unsafe())


    @staticmethod
    def get_count():
        return Exercise.all(live_only=True).count()

    def put(self):
        Setting.cached_exercises_date(str(datetime.datetime.now()))
        models.Model.put(self)
        Exercise.get_count(bust_cache=True)

    @staticmethod
    def get_dict(query, fxn_key):
        exercise_dict = {}
        for exercise in query.fetch(10000):
            exercise_dict[fxn_key(exercise)] = exercise
        return exercise_dict


class UserExercise(models.Model):

    user = models.ForeignKey(User)    
    exercise =  models.ForeignKey(Exercise) #models.CharField(max_length=60)
    #exercise_model = models.ForeignKey(Exercise)
    streak = models.IntegerField(default = 0)
    _progress = models.FloatField(default = 0.0)  # A continuous value >= 0.0, where 1.0 means proficiency. This measure abstracts away the internal proficiency model.
    longest_streak = models.IntegerField(default = 0)
    first_done = models.DateTimeField(auto_now_add=True)
    last_done = models.DateTimeField(auto_now_add=True)
    total_done = models.IntegerField(default = 0)
    total_correct = models.IntegerField(default = 0)
    last_review = models.DateTimeField(default=datetime.datetime.min)
    review_interval_secs = models.IntegerField(default=(60 * 60 * 24 * consts.DEFAULT_REVIEW_INTERVAL_DAYS)) # Default 7 days until review
    proficient_date = models.DateTimeField(default="2012-01-01 00:00:00")
    seconds_per_fast_problem = models.FloatField(default = consts.MIN_SECONDS_PER_FAST_PROBLEM) # Seconds expected to finish a problem 'quickly' for badge calculation
    summative = models.BooleanField(default=False)
    #_accuracy_model = object_property.ObjectField()  # Stateful function object that estimates P(next problem correct). May not exist for old UserExercise objects (but will be created when needed).

    _USER_EXERCISE_KEY_FORMAT = "UserExercise.all().filter('user = '%s')"

    _serialize_blacklist = ["review_interval_secs", "_progress", "_accuracy_model"]

    #_MIN_PROBLEMS_FROM_ACCURACY_MODEL = AccuracyModel.min_streak_till_threshold(consts.PROFICIENCY_ACCURACY_THRESHOLD)
    #_MIN_PROBLEMS_REQUIRED = max(_MIN_PROBLEMS_FROM_ACCURACY_MODEL, consts.MIN_PROBLEMS_IMPOSED)

    # Bound function objects to normalize the progress bar display from a probability
    # TODO(david): This is a bit of a hack to not have the normalizer move too
    #     slowly if the user got a lot of wrongs.
    #_all_correct_normalizer = InvFnExponentialNormalizer(
    #    accuracy_model = AccuracyModel().update(correct=False),
    #    proficiency_threshold = AccuracyModel.simulate([True] * _MIN_PROBLEMS_REQUIRED)
    #).normalize
    #_had_wrong_normalizer = InvFnExponentialNormalizer(
    #    accuracy_model = AccuracyModel().update([False] * 3),
    #    proficiency_threshold = consts.PROFICIENCY_ACCURACY_THRESHOLD
    #).normalize

    @property
    def exercise_states(self):
        user_exercise_graph = self.get_user_exercise_graph()
        if user_exercise_graph:
            return user_exercise_graph.states(self.exercise)
        return None

    @property
    def num_milestones(self):
        return self.exercise_model.num_milestones

    def accuracy_model(self):
        if self._accuracy_model is None:
            self._accuracy_model = AccuracyModel(self)
        return self._accuracy_model

    # Faciliate transition for old objects that did not have the _progress property
    @property
    #@clamp(0.0, 1.0)
    def progress(self):
        if self._progress is None:
            self._progress = self._get_progress_from_current_state()
        return self._progress

    def update_proficiency_model(self, correct):
        if not correct:
            self.streak = 0

        self.accuracy_model().update(correct)
        self._progress = self._get_progress_from_current_state()

    #@clamp(0.0, 1.0)
    def _get_progress_from_current_state(self):

        if self.total_correct == 0:
            return 0.0

        prediction = self.accuracy_model().predict()

        if self.accuracy_model().total_done <= self.accuracy_model().total_correct():
            # Impose a minimum number of problems required to be done.
            normalized_prediction = UserExercise._all_correct_normalizer(prediction)
        else:
            normalized_prediction = UserExercise._had_wrong_normalizer(prediction)

        if self.summative:
            if normalized_prediction >= 1.0:
                # The user just crossed a challenge barrier. Reset their
                # accuracy model to start fresh.
                self._accuracy_model = AccuracyModel()

            milestones_completed = math.floor(self._progress * self.num_milestones)
            return float(milestones_completed + normalized_prediction) / self.num_milestones

        else:
            return normalized_prediction

    @staticmethod
    def to_progress_display(num):
        return '%.0f%%' % math.floor(num * 100.0) if num <= consts.MAX_PROGRESS_SHOWN else 'Max'

    def progress_display(self):
        return UserExercise.to_progress_display(self.progress)

    @staticmethod
    def get_key_for_email(email):
        return UserExercise._USER_EXERCISE_KEY_FORMAT % email

    @staticmethod
    def get_for_user_data(user_data):
        query = UserExercise.all()
        query.filter('user =', user_data.user)
        return query

    def get_user_data(self):
        user_data = None

        if hasattr(self, "_user_data"):
            user_data = self._user_data
        else:
            user_data = UserData.get_from_models.key_email(self.user.email())

        if not user_data:
            logging.critical("Empty user data for UserExercise w/ .user = %s" % self.user)

        return user_data

    def get_user_exercise_graph(self):
        user_exercise_graph = None

        if hasattr(self, "_user_exercise_graph"):
            user_exercise_graph = self._user_exercise_graph
        else:
            user_exercise_graph = UserExerciseGraph.get(self.get_user_data())

        return user_exercise_graph

    def belongs_to(self, user_data):
        return user_data and self.user.email().lower() == user_data.key_email.lower()

    def is_struggling(self, struggling_model=None):
        """ Whether or not the user is currently "struggling" in this exercise
        for a given struggling model. Note that regardless of struggling model,
        if the last question was correct, the student is not considered
        struggling.
        """
        if self.has_been_proficient():
            return False

        return self.history_indicates_struggling(struggling_model)

    # TODO(benkomalo): collapse this method with is_struggling above.
    def history_indicates_struggling(self, struggling_model=None):
        """ Whether or not the history of answers indicates that the user
        is struggling on this exercise.

        Does not take into consideration if the last question was correct. """

        if struggling_model is None or struggling_model == 'old':
            return self._is_struggling_old()
        else:
            # accuracy based model.
            param = float(struggling_model.split('_')[1])
            return self.accuracy_model().is_struggling(
                    param=param,
                    minimum_accuracy=consts.PROFICIENCY_ACCURACY_THRESHOLD,
                    minimum_attempts=consts.MIN_PROBLEMS_IMPOSED)
    def _is_struggling_old(self):
        return self.streak == 0 and self.total_done > 20

    @staticmethod
    @clamp(datetime.timedelta(days=consts.MIN_REVIEW_INTERVAL_DAYS),
            datetime.timedelta(days=consts.MAX_REVIEW_INTERVAL_DAYS))
    def get_review_interval_from_seconds(seconds):
        return datetime.timedelta(seconds=seconds)

    def has_been_proficient(self):
        return self.proficient_date is not None

    def get_review_interval(self):
        return UserExercise.get_review_interval_from_seconds(self.review_interval_secs)

    def schedule_review(self, correct, now=None):
        if now is None:
            now = datetime.datetime.now()

        # If the user is not now and never has been proficient, don't schedule a review
        if self.progress < 1.0 and not self.has_been_proficient():
            return

        # If the user is hitting a new streak either for the first time or after having lost
        # proficiency, reset their review interval counter.
        if self.progress >= 1.0:
            self.review_interval_secs = 60 * 60 * 24 * consts.DEFAULT_REVIEW_INTERVAL_DAYS
        review_interval = self.get_review_interval()

        # If we correctly did this review while it was in a review state, and
        # the previous review was correct, extend the review interval
        if correct and self.last_review != datetime.datetime.min:
            time_since_last_review = now - self.last_review
            if time_since_last_review >= review_interval:
                review_interval = time_since_last_review * 2

        if correct:
            self.last_review = now
        else:
            self.last_review = datetime.datetime.min
            review_interval = review_interval // 2

        self.review_interval_secs = review_interval.days * 86400 + review_interval.seconds

    def set_proficient(self, user_data):
        if self.exercise in user_data.proficient_exercises:
            return

        self.proficient_date = datetime.datetime.now()

        user_data.proficient_exercises.append(self.exercise)
        user_data.need_to_reassess = True
        user_data.put()

        util_notify.update(user_data, self, False, True)

        if self.exercise in UserData.conversion_test_hard_exercises:
            bingo('hints_gained_proficiency_hard_binary')
        elif self.exercise in UserData.conversion_test_easy_exercises:
            bingo('hints_gained_proficiency_easy_binary')

    @classmethod
    def from_json(cls, json, user_data):
        '''This method exists for testing convenience only. It's called only
        by code that runs in exclusively in development mode. Do not rely on
        this method in production code. If you need to break this code to
        implement some new feature, feel free!
        '''
        exercise = Exercise.get_by_name(json['exercise'])
        if not exercise:
            return None

        # this is probably completely broken as we don't serialize anywhere near
        # all the properties that UserExercise has. Still, let's see if it works
        return cls(
            key_name=exercise.name,
            parent=user_data,
            user=user_data.user,
            exercise=exercise.name,
            exercise_model=exercise,
            streak=int(json['streak']),
            longest_streak=int(json['longest_streak']),
            first_done=util.parse_iso8601(json['first_done']),
            last_done=util.coalesce(util.parse_iso8601, json['last_done']),
            total_done=int(json['total_done']),
            summative=bool(json['summative']),
            _accuracy_model=AccuracyModel()
        )



class ProblemLog(models.Model):

    user =  models.ForeignKey(User)   
    exercise =  models.ForeignKey(Exercise)
    correct = models.BooleanField(default = False)
    time_done = models.DateTimeField(auto_now_add=True)
    time_taken = models.IntegerField(default = 0)
    hint_time_taken_list = models.CommaSeparatedIntegerField(max_length=300)
    hint_after_attempt_list = models.CommaSeparatedIntegerField(max_length=300)
    count_hints = models.IntegerField(default = 0)
    problem_number = models.IntegerField(default = -1) # Used to reproduce problems
    exercise_non_summative = models.CharField(max_length=100) # Used to reproduce problems from summative exercises
    hint_used = models.BooleanField(default = False)
    points_earned = models.IntegerField(default = 0)
    earned_proficiency = models.BooleanField(default = False) # True if proficiency was earned on this problem
    suggested = models.BooleanField(default = False) # True if the exercise was suggested to the user
    review_mode = models.BooleanField(default = False) # True if the problem was done while in review mode
    sha1 = models.TextField()
    seed = models.TextField()
    problem_type = models.CharField(max_length=100)
    count_attempts = models.IntegerField(default = 0)
    time_taken_attempts = models.CommaSeparatedIntegerField(max_length=300)
    attempts = models.TextField()
    random_float = models.FloatField(default = 0.0) # Add a random float in [0, 1) for easy random sampling
    ip_address = models.CharField(max_length=20)
    @classmethod
    def key_for(cls, user_data, exid, problem_number):
        return "problemlog_%s_%s_%s" % (user_data.email, exid,
            problem_number)

    @classmethod
    def from_json(cls, json, user_data, exercise):
        '''This method exists for testing convenience only. It's called only
        by code that runs in exclusively in development mode. Do not rely on
        this method in production code. If you need to break this code to
        implement some new feature, feel free!
        '''
        problem_number = int(json['problem_number'])
        return cls(
            attempts=json['attempts'],
            correct=bool(json['correct']),
            count_attempts=int(json['count_attempts']),
            count_hints=int(json['count_hints']),
            earned_proficiency=bool(json['earned_proficiency']),
            exercise=exercise.name,
            exercise_non_summative=json['exercise_non_summative'],
            hint_after_attempt_list=json['hint_after_attempt_list'],
            hint_time_taken_list=json['hint_time_taken_list'],
            hint_used=bool(json['hint_used']),
            ip_address=json['ip_address'],
            key_name=cls.key_for(user_data, exercise.name, problem_number),
            points_earned=int(json['points_earned']),
            problem_number=problem_number,
            problem_type=json['problem_type'],
            random_float=json['random_float'],
            review_mode=bool(json['review_mode']),
            seed=json['seed'],
            sha1=json['sha1'],
            suggested=bool(json['suggested']),
            time_done=util.parse_iso8601(json['time_done']),
            time_taken=int(json['time_taken']),
            time_taken_attempts=json['time_taken_attempts'],
            user=user_data.user,
        )

    def put(self):
        if self.random_float is None:
            self.random_float = random.random()
        models.Model.put(self)

    @property
    def ka_url(self):
        return util.absolute_url("/exercise/%s?problem_number=%s" % \
            (self.exercise, self.problem_number))

    @staticmethod
    def get_for_user_data_between_dts(user_data, dt_a, dt_b):
        query = ProblemLog.all()
        query.filter('user =', user_data.user)
        query.filter('time_done >=', dt_a)
        query.filter('time_done <', dt_b)

        query.order('time_done')

        return query

    def time_taken_capped_for_reporting(self):
        # For reporting's sake, we cap the amount of time that you can be considered to be
        # working on a single problem at 60 minutes. If you've left your browser open
        # longer, you're probably not actively working on the problem.
        return min(consts.MAX_WORKING_ON_PROBLEM_SECONDS, self.time_taken)

    def time_started(self):
        return self.time_done - datetime.timedelta(seconds = self.time_taken_capped_for_reporting())

    def time_ended(self):
        return self.time_done

    def minutes_spent(self):
        return util.minutes_between(self.time_started(), self.time_ended())

    # commit_problem_log is used by our deferred problem log insertion process
    def commit_problem_log(problem_log_source, user_data = None):
        try:
            if not problem_log_source or not problem_log_source.key().name:
                logging.critical("Skipping problem log commit due to missing problem_log_source or key().name")
                return
        except models.NotSavedError:
            # Handle special case during new exercise deploy
            logging.critical("Skipping problem log commit due to models.NotSavedError")
            return

        if problem_log_source.count_attempts > 1000:
            logging.info("Ignoring attempt to write problem log w/ attempts over 1000.")
            return

    # This does not have the same behavior as .insert(). This is used because
    # tasks can be run out of order so we extend the list as needed and insert
    # values.
    def insert_in_position(index, items, val, filler):
        if index >= len(items):
            items.extend([filler] * (index + 1 - len(items)))
        items[index] = val

    # Committing transaction combines existing problem log with any followup attempts
    def txn():
        problem_log = ProblemLog.get_by_key_name(problem_log_source.key().name())

        if not problem_log:
            problem_log = ProblemLog(
                key_name = problem_log_source.key().name(),
                user = problem_log_source.user,
                exercise = problem_log_source.exercise,
                problem_number = problem_log_source.problem_number,
                time_done = problem_log_source.time_done,
                sha1 = problem_log_source.sha1,
                seed = problem_log_source.seed,
                problem_type = problem_log_source.problem_type,
                suggested = problem_log_source.suggested,
                exercise_non_summative = problem_log_source.exercise_non_summative,
                ip_address = problem_log_source.ip_address,
                review_mode = problem_log_source.review_mode,
        )

        problem_log.count_hints = max(problem_log.count_hints, problem_log_source.count_hints)
        problem_log.hint_used = problem_log.count_hints > 0
        index_attempt = max(0, problem_log_source.count_attempts - 1)

        # Bump up attempt count
        if problem_log_source.attempts[0] != "hint": # attempt
            if index_attempt < len(problem_log.time_taken_attempts) \
               and problem_log.time_taken_attempts[index_attempt] != -1:
                # This attempt has already been logged. Ignore this dupe taskqueue execution.
                logging.info("Skipping problem log commit due to dupe taskqueue\
                    execution for attempt: %s, key.name: %s" % \
                    (index_attempt, problem_log_source.key().name()))
                return

            problem_log.count_attempts += 1

            # Add time_taken for this individual attempt
            problem_log.time_taken += problem_log_source.time_taken
            insert_in_position(index_attempt, problem_log.time_taken_attempts, problem_log_source.time_taken, filler=-1)
            # Add actual attempt content
            insert_in_position(index_attempt, problem_log.attempts, problem_log_source.attempts[0], filler="")

            # Proficiency earned should never change per problem
            problem_log.earned_proficiency = problem_log.earned_proficiency or \
                problem_log_source.earned_proficiency

        else: # hint
            index_hint = max(0, problem_log_source.count_hints - 1)

            if index_hint < len(problem_log.hint_time_taken_list) \
               and problem_log.hint_time_taken_list[index_hint] != -1:
                # This attempt has already been logged. Ignore this dupe taskqueue execution.
                return

            # Add time taken for hint
            insert_in_position(index_hint, problem_log.hint_time_taken_list, problem_log_source.time_taken, filler=-1)

            # Add attempt number this hint follows
            insert_in_position(index_hint, problem_log.hint_after_attempt_list, problem_log_source.count_attempts, filler=-1)

        # Points should only be earned once per problem, regardless of attempt count
        problem_log.points_earned = max(problem_log.points_earned, problem_log_source.points_earned)
        # Correct cannot be changed from False to True after first attempt
        problem_log.correct = (problem_log_source.count_attempts == 1 or problem_log.correct) and problem_log_source.correct and not problem_log.count_hints

        logging.info(problem_log.time_ended())
        problem_log.put()


    #models.run_in_transaction(txn)
    #transaction.commit(txn)                                                                                                                                      
class UserData(models.Model):
    # Canonical reference to the user entity. Avoid referencing this directly
    # as the fields of this property can change; only the ID is stable and
    # user_id can be used as a unique identifier instead.
    user = User

    # Deprecated - this was used to represent the current e-mail address of the
    # user but is no longer relevant. Do not use - see user_id instead.
    current_user = User

    # An opaque and uniquely identifying string for a user - this is stable
    # even if the user changes her e-mail.
    user_id = models.CharField(max_length=250)

    # A uniquely identifying string for a user. This is not stable and can
    # change if a user changes her e-mail. This is not actually always an
    # e-mail; for non-Google users, this can be a
    # URI like http://facebookid.khanacademy.org/1234
    user_email = models.CharField(max_length=250)

    # A human-readable name that will be user-configurable.
    # Do not read or modify this directly! Instead, use the nickname property
    # and update_nickname method
    user_nickname = models.CharField(max_length=250)
    # A globally unique user-specified username,
    # which will be used in URLS like khanacademy.org/profile/<username>
    username = models.CharField(max_length=250,default="")

    moderator = models.BooleanField(default=False)
    developer = models.BooleanField(default=False)
    joined = models.DateTimeField(auto_now_add=True)
    last_login = models.DateTimeField()

    # Names of exercises in which the user is *explicitly* proficient
    proficient_exercises = models.TextField()  #object_property.StringListCompatTsvField()

    # Names of all exercises in which the user is proficient
    all_proficient_exercises = models.TextField() # object_property.StringListCompatTsvField()

    suggested_exercises = models.TextField()   #object_property.StringListCompatTsvField()
    badges = models.TextField()    #object_property.StringListCompatTsvField() # All awarded badges
    need_to_reassess = models.BooleanField()
    points = models.IntegerField(default=0)
    total_seconds_watched = models.IntegerField(default=0)

    # A list of email values corresponding to the "user" property of the coaches
    # for the user. Note: that it may not be the current, active email
    coaches = models.CharField(max_length=200)

    student_lists = models.TextField()
   # map_coords = models.StringField(indexed=False)
    expanded_all_exercises = models.BooleanField(default=True)
    _completed = models.IntegerField(default=-1)
    last_daily_summary = models.DateTimeField()
    last_badge_review = models.DateTimeField()
    last_activity = models.DateTimeField()
    start_consecutive_activity_date = models.DateTimeField()
    count_feedback_notification = models.IntegerField(default=-1)
    question_sort_order = models.IntegerField(default=-1)
    uservideocss_version = models.IntegerField(default=0)
    has_current_goals = models.BooleanField(default=False)

    # A list of badge names that the user has chosen to display publicly
    # Note that this list is not contiguous - it may have "holes" in it
    # indicated by the reserved string "__empty__"
    #public_badges = object_property.TsvField()

    # The name of the avatar the user has chosen. See avatar.util_avatar.py
    avatar_name = models.TextField()

    # Whether or not the user has indicated she wishes to have a public
    # profile (and can be searched, etc)
    is_profile_public = models.BooleanField(default=False)

    _serialize_blacklist = [
            "badges", "count_feemodels.ck_notification",
            "last_daily_summary", "need_to_reassess", "videos_completed",
            "moderator", "expanded_all_exercises", "question_sort_order",
            "last_login", "user", "current_user", "map_coords",
            "expanded_all_exercises", "user_nickname", "user_email",
            "seconds_since_joined", "has_current_goals", "public_badges",
            "avatar_name", "username", "is_profile_public"
    ]

    conversion_test_hard_exercises = set(['order_of_operations', 'graphing_points',
        'probability_1', 'domain_of_a_function', 'division_4',
        'ratio_word_problems', 'writing_expressions_1', 'ordering_numbers',
        'geometry_1', 'converting_mixed_numbers_and_improper_fractions'])
    conversion_test_easy_exercises = set(['counting_1', 'significant_figures_1', 'subtraction_1'])

    @property
    def nickname(self):
        """ Gets a human-friendly display name that the user can optionally set
        themselves. Will initially default to either the Facebook name or
        part of the user's e-mail.
        """

        # Note - we make a distinction between "None", which means the user has
        # never gotten or set their nickname, and the empty string, which means
        # the user has explicitly made an empty nickname
        if self.user_nickname is not None:
            return self.user_nickname

        return nicknames.get_default_nickname_for(self)

    def update_nickname(self, nickname=None):
        """ Updates the user's nickname and relevant indices and persists
        to the datastore.
        """
        if nickname is None:
            nickname = nicknames.get_default_nickname_for(self)
        new_name = nickname or ""
        # TODO: Fix this in a more systematic way
        # Ending script tags are special since we can put profile data in JSON
        # embedded inside an HTML. Until we can fix that problem in the jsonify
        # code, we temporarily disallow these as a stop gap.
        new_name = new_name.replace('</script>', '')
        if new_name != self.user_nickname:
            if nickname and not nicknames.is_valid_nickname(nickname):
                # The user picked a name, and it seems offensive. Reject it.
                return False

            self.user_nickname = new_name
            def txn():
                NicknameIndex.update_indices(self)
                self.put()
            models.run_in_transaction(txn)
        return True

    @property
    def email(self):
        return self.user_email

    @property
    def key_email(self):
        return self.user.email()

    @property
    def badge_counts(self):
        return util_badges.get_badge_counts(self)
    @property
    def prettified_user_email(self):
        if self.is_facebook_user:
            return "_fb" + self.user_email[len(FACEBOOK_ID_PREFIX):]
        elif self.is_phantom:
            return "nouser"
        else:
            return "_em" + urllib.quote(self.user_email)

    @staticmethod
    def get_from_url_segment(segment):
        username_or_email = None

        if segment:
            segment = urllib.unquote(segment)
            if segment.startswith("_fb"):
                username_or_email = segment.replace("_fb", FACEBOOK_ID_PREFIX)
            elif segment.startswith("_em"):
                username_or_email = segment.replace("_em", "")
            else:
                username_or_email = segment

        return UserData.get_from_username_or_email(username_or_email) 
    @property
    def profile_root(self):
        root = "/profile/"

        if self.username:
            root += self.username
        else:
            root += self.prettified_user_email

        return root

    @staticmethod
    #@request_cache.cache()
    def current():
        user_id = util.get_current_user_id(bust_cache=True)
        email = user_id

        google_user = users.get_current_user()
        if google_user:
            email = google_user.email()

        if user_id:
            # Once we have rekeyed legacy entities,
            # we will be able to simplify this.
            return  UserData.get_from_user_id(user_id) or \
                    UserData.get_from_models.key_email(email) or \
                    UserData.insert_for(user_id, email)
        return None

    @staticmethod
    def pre_phantom():
        return UserData.insert_for(PRE_PHANTOM_EMAIL, PRE_PHANTOM_EMAIL)

    @property
    def is_phantom(self):
        return util.is_phantom_user(self.user_id)

    @property
    def is_pre_phantom(self):
        return PRE_PHANTOM_EMAIL == self.user_email

    @property
    def seconds_since_joined(self):
        return util.seconds_since(self.joined)

    @staticmethod
    #@request_cache.cache_with_key_fxn(lambda user_id: "UserData_user_id:%s" % user_id)
    def get_from_user_id(user_id):
        if not user_id:
            return None

        query = UserData.all()
        query.filter('user_id =', user_id)
        query.order('-points') # Temporary workaround for issue 289
        return query.get()

    @staticmethod
    def get_from_user_input_email(email):
        if not email:
            return None

        query = UserData.all()
        query.filter('user_email =', email)
        query.order('-points') # Temporary workaround for issue 289

        return query.get()

    @staticmethod
    def get_from_username(username):
        if not username:
            return None
        canonical_username = UniqueUsername.get_canonical(username)
        if not canonical_username:
            return None
        query = UserData.all()
        query.filter('username =', canonical_username.username)
        return query.get()

    @staticmethod
    def get_from_models_key_email(email):
        if not email:
            return None

        query = UserData.all()
        query.filter('user =', users.User(email))
        query.order('-points') # Temporary workaround for issue 289

        return query.get()

    @staticmethod
    def get_from_username_or_email(username_or_email):
        if not username_or_email:
            return None

        user_data = None

        if UniqueUsername.is_valid_username(username_or_email):
            user_data = UserData.get_from_username(username_or_email)
        else:
            user_data = UserData.get_possibly_current_user(username_or_email)

        return user_data

    # Avoid an extra DB call in the (fairly often) case that the requested email
    # is the email of the currently logged-in user
    @staticmethod
    def get_possibly_current_user(email):
        if not email:
            return None

        user_data_current = UserData.current()
        if user_data_current and user_data_current.user_email == email:
            return user_data_current
        return UserData.get_from_user_input_email(email) or UserData.get_from_user_id(email)

    @classmethod
    def key_for(cls, user_id):
        return "user_id_key_%s" % user_id

    @staticmethod
    def get_possibly_current_user_by_username(username):
        if not username:
            return None

        user_data_current = UserData.current()
        if user_data_current and user_data_current.username == username:
            return user_data_current

        return UserData.get_from_username(username)

    @staticmethod
    def insert_for(user_id, email):
        if not user_id or not email:
            return None

        user = users.User(email)

        user_data = UserData.get_or_insert(
            key_name=UserData.key_for(user_id),
            user=user,
            current_user=user,
            user_id=user_id,
            moderator=False,
            last_login=datetime.datetime.now(),
            proficient_exercises=[],
            suggested_exercises=[],
            need_to_reassess=True,
            points=0,
            coaches=[],
            user_email=email

            )

        if not user_data.is_phantom:
            # Record that we now have one more registered user
            if (datetime.datetime.now() - user_data.joined).seconds < 60:
                # Extra safety check against user_data.joined in case some
                # subtle bug results in lots of calls to insert_for for
                # UserData objects with existing key_names.
                user_counter.add(1)

        return user_data

    def delete(self):
        logging.info("Deleting user data for %s with points %s" % (self.key_email, self.points))
        logging.info("Dumping user data for %s: %s" % (self.user_id, jsonify(self)))

        if not self.is_phantom:
            user_counter.add(-1)

        models.delete(self)
    def get_or_insert_exercise(self, exercise, allow_insert = True):
        if not exercise:
            return None

        exid = exercise.name
        userExercise = UserExercise.get_by_key_name(exid, parent=self)

        if not userExercise:
            # There are some old entities lying around that don't have keys.
            # We have to check for them here, but once we have reparented and rekeyed legacy entities,
            # this entire function can just be a call to .get_or_insert()
            query = UserExercise.all(keys_only = True)
            query.filter('user =', self.user)
            query.filter('exercise =', exid)
            query.order('-total_done') # Temporary workaround for issue 289

            # In order to guarantee consistency in the HR datastore, we need to query
            # via models.get for these old, parent-less entities.
            key_user_exercise = query.get()
            if key_user_exercise:
                userExercise = UserExercise.get(str(key_user_exercise))

        if allow_insert and not userExercise:
            userExercise = UserExercise.get_or_insert(
                key_name=exid,
                parent=self,
                user=self.user,
                exercise=exid,
                exercise_model=exercise,
                streak=0,
                _progress=0.0,
                longest_streak=0,
                first_done=datetime.datetime.now(),
                last_done=None,
                total_done=0,
                summative=exercise.summative,
                _accuracy_model=AccuracyModel(),
                )

        return userExercise
    def reassess_if_necessary(self, user_exercise_graph=None):
        if not self.need_to_reassess or self.all_proficient_exercises is None:
            return False

        if user_exercise_graph is None:
            user_exercise_graph = UserExerciseGraph.get(self)

        return self.reassess_from_graph(user_exercise_graph)

    def is_proficient_at(self, exid, exgraph=None):
        self.reassess_if_necessary(exgraph)
        return (exid in self.all_proficient_exercises)

    def is_explicitly_proficient_at(self, exid):
        return (exid in self.proficient_exercises)

    def is_suggested(self, exid):
        self.reassess_if_necessary()
        return (exid in self.suggested_exercises)

    def get_students_data(self):
        coach_email = self.key_email
        query = UserData.all().filter('coaches =', coach_email)
        students_data = [s for s in query.fetch(1000)]

        if coach_email.lower() != coach_email:
            students_set = set([s.key().id_or_name() for s in students_data])
            query = UserData.all().filter('coaches =', coach_email.lower())
            for student_data in query:
                if student_data.key().id_or_name() not in students_set:
                    students_data.append(student_data)
        return students_data

    def record_activity(self, dt_activity):

        # Make sure last_activity and start_consecutive_activity_date have values
        self.last_activity = self.last_activity or dt_activity
        self.start_consecutive_activity_date = self.start_consecutive_activity_date or dt_activity

        if dt_activity > self.last_activity:

            # If it has been over 40 hours since we last saw this user, restart
            # the consecutive activity streak.
            #
            # We allow for a lenient 40 hours in order to offer kinder timezone
            # interpretation.
            #
            # 36 hours wasn't quite enough. A user with activity at 8am on
            # Monday and 8:15pm on Tuesday would not have consecutive days of
            # activity.
            #
            # See http://meta.stackoverflow.com/questions/55483/proposed-consecutive-days-badge-tracking-change
            if util.hours_between(self.last_activity, dt_activity) >= 40:
                self.start_consecutive_activity_date = dt_activity

            self.last_activity = dt_activity

    def current_consecutive_activity_days(self):
        if not self.last_activity or not self.start_consecutive_activity_date:
            return 0
        dt_now = datetime.datetime.now()

        # If it has been over 40 hours since last activity, bail.
        if util.hours_between(self.last_activity, dt_now) >= 40:
            return 0

        return (self.last_activity - self.start_consecutive_activity_date).days

    def add_points(self, points):
        if self.points is None:
            self.points = 0

        if not hasattr(self, "_original_points"):
            self._original_points = self.points

        # Check if we crossed an interval of 2500 points
        if self.points % 2500 > (self.points + points) % 2500:
            util_notify.update(self, user_exercise=None, threshold=True)
        self.points += points

    def original_points(self):
        return getattr(self, "_original_points", 0)

